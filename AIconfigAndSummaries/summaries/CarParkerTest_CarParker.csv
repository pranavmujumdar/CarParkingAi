Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
60000,2.8421693,-0.034917396,0.0014147372,0.067403816,0.00029518825,-0.7263744809887033,893.7272727272727,-0.726374584978277
120000,2.760371,-0.078731894,0.00027083998,0.06732016,0.00028647447,-0.9206817517203463,950.8181818181819,-0.9206818618219007
180000,2.6927056,-0.08721138,0.00025421777,0.06758787,0.00027740156,-0.8969870304330646,946.3064516129032,-0.8969871392173152
240000,2.6520424,-0.07619439,0.00053313264,0.06746366,0.00026845315,-0.7675342655613838,887.6268656716418,-0.7675343677957556
300000,2.6786096,-0.07189584,0.0006780109,0.066516854,0.00025951845,-0.6753499386819278,852.8676470588235,-0.6753500381703762
360000,2.6288176,-0.020346355,0.0011614395,0.069261454,0.00025060202,-0.22667028038451642,655.7252747252747,-0.22667035517784265
420000,2.5663273,0.037676312,0.002357254,0.0683753,0.00024155503,-0.0004073665634981201,547.1296296296297,-0.0004074263420921785
480000,2.4492586,0.074349135,0.0025329376,0.07157078,0.00023248419,0.24619415505506315,445.125,0.246194107704522
